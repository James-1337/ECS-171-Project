{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8e9706bd-fe4e-45f4-be9f-dfeb9ec93d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "45f98861-9d85-4e93-9b0e-db776cc5ca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   age                            1000 non-null   int64  \n",
      " 1   gender                         1000 non-null   object \n",
      " 2   study_hours_per_day            1000 non-null   float64\n",
      " 3   social_media_hours             1000 non-null   float64\n",
      " 4   netflix_hours                  1000 non-null   float64\n",
      " 5   part_time_job                  1000 non-null   object \n",
      " 6   attendance_percentage          1000 non-null   float64\n",
      " 7   sleep_hours                    1000 non-null   float64\n",
      " 8   diet_quality                   1000 non-null   object \n",
      " 9   exercise_frequency             1000 non-null   int64  \n",
      " 10  parental_education_level       909 non-null    object \n",
      " 11  internet_quality               1000 non-null   object \n",
      " 12  mental_health_rating           1000 non-null   int64  \n",
      " 13  extracurricular_participation  1000 non-null   object \n",
      " 14  exam_score                     1000 non-null   float64\n",
      "dtypes: float64(6), int64(3), object(6)\n",
      "memory usage: 117.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"jayaantanaath/student-habits-vs-academic-performance\")\n",
    "df = pd.read_csv(path + '/student_habits_performance.csv')\n",
    "\n",
    "# Separate features and target\n",
    "df = df.drop(columns=['student_id'])\n",
    "X = df.drop(columns=['exam_score'])\n",
    "y = df['exam_score'].values\n",
    "\n",
    "# Identify column types\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Split data\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cf4354c9-3c36-4e96-9d9e-bd9c8b70823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed X_train_val shape: torch.Size([800, 25])\n",
      "Processed X_test shape: torch.Size([200, 25])\n",
      "gender unique values: ['Female' 'Male' 'Other']\n",
      "part_time_job unique values: ['No' 'Yes']\n",
      "diet_quality unique values: ['Fair' 'Good' 'Poor']\n",
      "parental_education_level unique values: ['Master' 'High School' 'Bachelor' nan]\n",
      "internet_quality unique values: ['Average' 'Poor' 'Good']\n",
      "extracurricular_participation unique values: ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "# Build preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_val_processed = preprocessor.fit_transform(X_train_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_val_tensor = torch.tensor(X_train_val_processed, dtype=torch.float32)\n",
    "y_train_val_tensor = torch.tensor(y_train_val.reshape(-1, 1), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "print(\"Processed X_train_val shape:\", X_train_val_tensor.shape)\n",
    "print(\"Processed X_test shape:\", X_test_tensor.shape)\n",
    "for col in ['gender', 'part_time_job', 'diet_quality', 'parental_education_level', 'internet_quality', 'extracurricular_participation']:\n",
    "    print(f\"{col} unique values:\", df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c875d1e1-52a7-46c5-a387-9cfefcb719ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class DeeperNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeeperNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0f6ada6d-c63e-4d0e-a7fb-29cf5aaa5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, X_tensor, y_tensor, learning_rate, batch_size, epochs=150, k_folds=5):\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    mses, rmses, maes, mapes, r2s = [], [], [], [], []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_tensor)):\n",
    "        X_train, X_val = X_tensor[train_idx], X_tensor[val_idx]\n",
    "        y_train, y_val = y_tensor[train_idx], y_tensor[val_idx]\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "        model = model_class(X_tensor.shape[1])\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = model(X_val)\n",
    "            val_preds_np = val_preds.numpy().flatten()\n",
    "            y_val_np = y_val.numpy().flatten()\n",
    "\n",
    "            # Compute metrics\n",
    "            mse = mean_squared_error(y_val_np, val_preds_np)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_val_np, val_preds_np)\n",
    "            mape = mean_absolute_percentage_error(y_val_np, val_preds_np) * 100\n",
    "            r2 = r2_score(y_val_np, val_preds_np)\n",
    "\n",
    "            mses.append(mse)\n",
    "            rmses.append(rmse)\n",
    "            maes.append(mae)\n",
    "            mapes.append(mape)\n",
    "            r2s.append(r2)\n",
    "\n",
    "    return np.mean(mses), np.mean(rmses), np.mean(maes), np.mean(mapes), np.mean(r2), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "44782a42-761f-4edb-9201-d902a27f4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the best model on the test set\n",
    "def test_model(model, X_test_tensor, y_test_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_preds = model(X_test_tensor)\n",
    "        test_preds_np = test_preds.numpy().flatten()\n",
    "        y_test_np = y_test_tensor.numpy().flatten()\n",
    "\n",
    "        test_mse = mean_squared_error(y_test_np, test_preds_np)\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_mae = mean_absolute_error(y_test_np, test_preds_np)\n",
    "        test_mape = mean_absolute_percentage_error(y_test_np, test_preds_np) * 100\n",
    "        test_r2 = r2_score(y_test_np, test_preds_np)\n",
    "\n",
    "    return test_mse, test_rmse, test_mae, test_mape, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "39a0cd43-2784-4b49-9a08-0598749c857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SimpleNet with lr=0.0001, batch_size=16, k_folds=3\n",
      "Validation | MSE: 34.6189, RMSE: 5.8816, MAE: 4.6339, MAPE: 7.23%, R2: 0.8691\n",
      "Test | MSE: 27.0533, RMSE: 5.2013, MAE: 4.2137, MAPE: 6.86%, R2: 0.8945\n",
      "\n",
      "Evaluating DeepNet with lr=0.0001, batch_size=16, k_folds=3\n",
      "Validation | MSE: 48.8134, RMSE: 6.9788, MAE: 5.5530, MAPE: 8.73%, R2: 0.8052\n",
      "Test | MSE: 39.6475, RMSE: 6.2966, MAE: 5.1025, MAPE: 8.21%, R2: 0.8454\n",
      "\n",
      "Evaluating DeeperNet with lr=0.0001, batch_size=16, k_folds=3\n",
      "Validation | MSE: 47.5831, RMSE: 6.8969, MAE: 5.4734, MAPE: 8.42%, R2: 0.8243\n",
      "Test | MSE: 44.1342, RMSE: 6.6434, MAE: 5.4873, MAPE: 8.67%, R2: 0.8279\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0001, batch_size=32, k_folds=3\n",
      "Validation | MSE: 31.8983, RMSE: 5.6443, MAE: 4.4526, MAPE: 6.89%, R2: 0.8772\n",
      "Test | MSE: 26.8286, RMSE: 5.1796, MAE: 4.2267, MAPE: 6.95%, R2: 0.8954\n",
      "\n",
      "Evaluating DeepNet with lr=0.0001, batch_size=32, k_folds=3\n",
      "Validation | MSE: 41.5368, RMSE: 6.4374, MAE: 5.0989, MAPE: 7.98%, R2: 0.8340\n",
      "Test | MSE: 30.1482, RMSE: 5.4907, MAE: 4.4323, MAPE: 7.06%, R2: 0.8824\n",
      "\n",
      "Evaluating DeeperNet with lr=0.0001, batch_size=32, k_folds=3\n",
      "Validation | MSE: 51.4534, RMSE: 7.1714, MAE: 5.7407, MAPE: 8.79%, R2: 0.8079\n",
      "Test | MSE: 47.5866, RMSE: 6.8983, MAE: 5.5101, MAPE: 8.53%, R2: 0.8144\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0001, batch_size=64, k_folds=3\n",
      "Validation | MSE: 31.4575, RMSE: 5.6045, MAE: 4.4151, MAPE: 6.85%, R2: 0.8789\n",
      "Test | MSE: 26.7412, RMSE: 5.1712, MAE: 4.2158, MAPE: 6.97%, R2: 0.8957\n",
      "\n",
      "Evaluating DeepNet with lr=0.0001, batch_size=64, k_folds=3\n",
      "Validation | MSE: 36.8588, RMSE: 6.0681, MAE: 4.8334, MAPE: 7.52%, R2: 0.8591\n",
      "Test | MSE: 31.2954, RMSE: 5.5942, MAE: 4.5569, MAPE: 7.41%, R2: 0.8780\n",
      "\n",
      "Evaluating DeeperNet with lr=0.0001, batch_size=64, k_folds=3\n",
      "Validation | MSE: 49.3369, RMSE: 7.0186, MAE: 5.6636, MAPE: 8.71%, R2: 0.8412\n",
      "Test | MSE: 43.9832, RMSE: 6.6320, MAE: 5.4331, MAPE: 8.46%, R2: 0.8285\n",
      "\n",
      "Evaluating SimpleNet with lr=5e-05, batch_size=16, k_folds=3\n",
      "Validation | MSE: 31.8011, RMSE: 5.6344, MAE: 4.4575, MAPE: 6.91%, R2: 0.8752\n",
      "Test | MSE: 27.4194, RMSE: 5.2363, MAE: 4.2794, MAPE: 6.99%, R2: 0.8931\n",
      "\n",
      "Evaluating DeepNet with lr=5e-05, batch_size=16, k_folds=3\n",
      "Validation | MSE: 43.7170, RMSE: 6.6106, MAE: 5.2958, MAPE: 8.22%, R2: 0.8397\n",
      "Test | MSE: 35.0531, RMSE: 5.9206, MAE: 4.7710, MAPE: 7.64%, R2: 0.8633\n",
      "\n",
      "Evaluating DeeperNet with lr=5e-05, batch_size=16, k_folds=3\n",
      "Validation | MSE: 49.0091, RMSE: 6.9979, MAE: 5.5641, MAPE: 8.58%, R2: 0.8166\n",
      "Test | MSE: 42.6596, RMSE: 6.5314, MAE: 5.3312, MAPE: 8.41%, R2: 0.8336\n",
      "\n",
      "Evaluating SimpleNet with lr=5e-05, batch_size=32, k_folds=3\n",
      "Validation | MSE: 31.3092, RMSE: 5.5916, MAE: 4.3966, MAPE: 6.82%, R2: 0.8791\n",
      "Test | MSE: 27.1260, RMSE: 5.2083, MAE: 4.2696, MAPE: 7.08%, R2: 0.8942\n",
      "\n",
      "Evaluating DeepNet with lr=5e-05, batch_size=32, k_folds=3\n",
      "Validation | MSE: 35.3665, RMSE: 5.9434, MAE: 4.7277, MAPE: 7.42%, R2: 0.8633\n",
      "Test | MSE: 29.0434, RMSE: 5.3892, MAE: 4.4195, MAPE: 7.07%, R2: 0.8867\n",
      "\n",
      "Evaluating DeeperNet with lr=5e-05, batch_size=32, k_folds=3\n",
      "Validation | MSE: 50.3417, RMSE: 7.0899, MAE: 5.6381, MAPE: 8.77%, R2: 0.8049\n",
      "Test | MSE: 46.9289, RMSE: 6.8505, MAE: 5.4067, MAPE: 8.70%, R2: 0.8170\n",
      "\n",
      "Evaluating SimpleNet with lr=5e-05, batch_size=64, k_folds=3\n",
      "Validation | MSE: 31.3002, RMSE: 5.5908, MAE: 4.4105, MAPE: 6.82%, R2: 0.8796\n",
      "Test | MSE: 27.2408, RMSE: 5.2193, MAE: 4.2507, MAPE: 7.01%, R2: 0.8938\n",
      "\n",
      "Evaluating DeepNet with lr=5e-05, batch_size=64, k_folds=3\n",
      "Validation | MSE: 34.5014, RMSE: 5.8651, MAE: 4.5890, MAPE: 7.17%, R2: 0.8602\n",
      "Test | MSE: 27.7930, RMSE: 5.2719, MAE: 4.2914, MAPE: 7.17%, R2: 0.8916\n",
      "\n",
      "Evaluating DeeperNet with lr=5e-05, batch_size=64, k_folds=3\n",
      "Validation | MSE: 45.0767, RMSE: 6.7131, MAE: 5.2960, MAPE: 8.19%, R2: 0.8359\n",
      "Test | MSE: 37.3727, RMSE: 6.1133, MAE: 5.1188, MAPE: 8.15%, R2: 0.8543\n",
      "\n",
      "Evaluating SimpleNet with lr=1e-05, batch_size=16, k_folds=3\n",
      "Validation | MSE: 31.5101, RMSE: 5.6092, MAE: 4.4153, MAPE: 6.84%, R2: 0.8794\n",
      "Test | MSE: 27.3068, RMSE: 5.2256, MAE: 4.2717, MAPE: 7.08%, R2: 0.8935\n",
      "\n",
      "Evaluating DeepNet with lr=1e-05, batch_size=16, k_folds=3\n",
      "Validation | MSE: 32.7069, RMSE: 5.7137, MAE: 4.4702, MAPE: 6.93%, R2: 0.8717\n",
      "Test | MSE: 26.4891, RMSE: 5.1468, MAE: 4.1689, MAPE: 6.87%, R2: 0.8967\n",
      "\n",
      "Evaluating DeeperNet with lr=1e-05, batch_size=16, k_folds=3\n",
      "Validation | MSE: 40.9547, RMSE: 6.3936, MAE: 5.1185, MAPE: 8.00%, R2: 0.8407\n",
      "Test | MSE: 35.2371, RMSE: 5.9361, MAE: 4.9501, MAPE: 7.84%, R2: 0.8626\n",
      "\n",
      "Evaluating SimpleNet with lr=1e-05, batch_size=32, k_folds=3\n",
      "Validation | MSE: 31.8722, RMSE: 5.6416, MAE: 4.4297, MAPE: 6.87%, R2: 0.8797\n",
      "Test | MSE: 27.6225, RMSE: 5.2557, MAE: 4.2990, MAPE: 7.15%, R2: 0.8923\n",
      "\n",
      "Evaluating DeepNet with lr=1e-05, batch_size=32, k_folds=3\n",
      "Validation | MSE: 32.7077, RMSE: 5.7162, MAE: 4.4734, MAPE: 6.93%, R2: 0.8753\n",
      "Test | MSE: 27.7417, RMSE: 5.2670, MAE: 4.2582, MAPE: 7.07%, R2: 0.8918\n",
      "\n",
      "Evaluating DeeperNet with lr=1e-05, batch_size=32, k_folds=3\n",
      "Validation | MSE: 35.5591, RMSE: 5.9603, MAE: 4.7313, MAPE: 7.45%, R2: 0.8646\n",
      "Test | MSE: 28.0787, RMSE: 5.2989, MAE: 4.3620, MAPE: 6.99%, R2: 0.8905\n",
      "\n",
      "Evaluating SimpleNet with lr=1e-05, batch_size=64, k_folds=3\n",
      "Validation | MSE: 33.8104, RMSE: 5.8112, MAE: 4.5405, MAPE: 7.04%, R2: 0.8792\n",
      "Test | MSE: 28.6049, RMSE: 5.3484, MAE: 4.3950, MAPE: 7.37%, R2: 0.8884\n",
      "\n",
      "Evaluating DeepNet with lr=1e-05, batch_size=64, k_folds=3\n",
      "Validation | MSE: 32.5661, RMSE: 5.7003, MAE: 4.4661, MAPE: 6.94%, R2: 0.8718\n",
      "Test | MSE: 29.9843, RMSE: 5.4758, MAE: 4.4154, MAPE: 7.38%, R2: 0.8831\n",
      "\n",
      "Evaluating DeeperNet with lr=1e-05, batch_size=64, k_folds=3\n",
      "Validation | MSE: 34.9255, RMSE: 5.9041, MAE: 4.6428, MAPE: 7.21%, R2: 0.8624\n",
      "Test | MSE: 29.2615, RMSE: 5.4094, MAE: 4.4016, MAPE: 7.26%, R2: 0.8859\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0001, batch_size=16, k_folds=5\n",
      "Validation | MSE: 33.1418, RMSE: 5.7364, MAE: 4.5550, MAPE: 7.03%, R2: 0.8821\n",
      "Test | MSE: 28.2801, RMSE: 5.3179, MAE: 4.3489, MAPE: 6.90%, R2: 0.8897\n",
      "\n",
      "Evaluating DeepNet with lr=0.0001, batch_size=16, k_folds=5\n",
      "Validation | MSE: 47.7079, RMSE: 6.8955, MAE: 5.5044, MAPE: 8.60%, R2: 0.8131\n",
      "Test | MSE: 39.9040, RMSE: 6.3170, MAE: 5.1901, MAPE: 8.17%, R2: 0.8444\n",
      "\n",
      "Evaluating DeeperNet with lr=0.0001, batch_size=16, k_folds=5\n",
      "Validation | MSE: 51.1760, RMSE: 7.1434, MAE: 5.6977, MAPE: 8.77%, R2: 0.8121\n",
      "Test | MSE: 42.2216, RMSE: 6.4978, MAE: 5.2560, MAPE: 8.16%, R2: 0.8353\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0001, batch_size=32, k_folds=5\n",
      "Validation | MSE: 31.4006, RMSE: 5.5815, MAE: 4.3833, MAPE: 6.81%, R2: 0.8888\n",
      "Test | MSE: 26.9914, RMSE: 5.1953, MAE: 4.2061, MAPE: 6.98%, R2: 0.8947\n",
      "\n",
      "Evaluating DeepNet with lr=0.0001, batch_size=32, k_folds=5\n",
      "Validation | MSE: 39.0486, RMSE: 6.2434, MAE: 4.9598, MAPE: 7.69%, R2: 0.8684\n",
      "Test | MSE: 32.7763, RMSE: 5.7251, MAE: 4.5842, MAPE: 7.19%, R2: 0.8722\n",
      "\n",
      "Evaluating DeeperNet with lr=0.0001, batch_size=32, k_folds=5\n",
      "Validation | MSE: 53.0374, RMSE: 7.2800, MAE: 5.8214, MAPE: 8.96%, R2: 0.8120\n",
      "Test | MSE: 46.3786, RMSE: 6.8102, MAE: 5.5247, MAPE: 8.67%, R2: 0.8191\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0001, batch_size=64, k_folds=5\n",
      "Validation | MSE: 31.0204, RMSE: 5.5460, MAE: 4.3706, MAPE: 6.76%, R2: 0.8906\n",
      "Test | MSE: 26.7388, RMSE: 5.1710, MAE: 4.2306, MAPE: 6.93%, R2: 0.8957\n",
      "\n",
      "Evaluating DeepNet with lr=0.0001, batch_size=64, k_folds=5\n",
      "Validation | MSE: 36.4943, RMSE: 6.0178, MAE: 4.7410, MAPE: 7.40%, R2: 0.8623\n",
      "Test | MSE: 29.7543, RMSE: 5.4547, MAE: 4.3947, MAPE: 7.13%, R2: 0.8840\n",
      "\n",
      "Evaluating DeeperNet with lr=0.0001, batch_size=64, k_folds=5\n",
      "Validation | MSE: 51.0208, RMSE: 7.1378, MAE: 5.7133, MAPE: 8.81%, R2: 0.7846\n",
      "Test | MSE: 43.5145, RMSE: 6.5966, MAE: 5.1166, MAPE: 7.95%, R2: 0.8303\n",
      "\n",
      "Evaluating SimpleNet with lr=5e-05, batch_size=16, k_folds=5\n",
      "Validation | MSE: 31.2704, RMSE: 5.5732, MAE: 4.3869, MAPE: 6.80%, R2: 0.8891\n",
      "Test | MSE: 26.4019, RMSE: 5.1383, MAE: 4.1536, MAPE: 6.83%, R2: 0.8970\n",
      "\n",
      "Evaluating DeepNet with lr=5e-05, batch_size=16, k_folds=5\n",
      "Validation | MSE: 40.2546, RMSE: 6.3391, MAE: 5.0666, MAPE: 7.86%, R2: 0.8566\n",
      "Test | MSE: 34.6968, RMSE: 5.8904, MAE: 4.8482, MAPE: 7.63%, R2: 0.8647\n",
      "\n",
      "Evaluating DeeperNet with lr=5e-05, batch_size=16, k_folds=5\n",
      "Validation | MSE: 50.4589, RMSE: 7.0889, MAE: 5.7174, MAPE: 8.71%, R2: 0.7943\n",
      "Test | MSE: 46.1067, RMSE: 6.7902, MAE: 5.4113, MAPE: 8.54%, R2: 0.8202\n",
      "\n",
      "Evaluating SimpleNet with lr=5e-05, batch_size=32, k_folds=5\n",
      "Validation | MSE: 30.7628, RMSE: 5.5251, MAE: 4.3498, MAPE: 6.72%, R2: 0.8910\n",
      "Test | MSE: 26.6891, RMSE: 5.1661, MAE: 4.2081, MAPE: 6.92%, R2: 0.8959\n",
      "\n",
      "Evaluating DeepNet with lr=5e-05, batch_size=32, k_folds=5\n",
      "Validation | MSE: 33.6908, RMSE: 5.7889, MAE: 4.6195, MAPE: 7.08%, R2: 0.8782\n",
      "Test | MSE: 27.0870, RMSE: 5.2045, MAE: 4.2554, MAPE: 6.68%, R2: 0.8944\n",
      "\n",
      "Evaluating DeeperNet with lr=5e-05, batch_size=32, k_folds=5\n",
      "Validation | MSE: 47.7944, RMSE: 6.9100, MAE: 5.5161, MAPE: 8.55%, R2: 0.8192\n",
      "Test | MSE: 44.1821, RMSE: 6.6470, MAE: 5.4848, MAPE: 8.66%, R2: 0.8277\n",
      "\n",
      "Evaluating SimpleNet with lr=5e-05, batch_size=64, k_folds=5\n",
      "Validation | MSE: 30.8257, RMSE: 5.5295, MAE: 4.3603, MAPE: 6.75%, R2: 0.8909\n",
      "Test | MSE: 26.9902, RMSE: 5.1952, MAE: 4.2518, MAPE: 7.03%, R2: 0.8947\n",
      "\n",
      "Evaluating DeepNet with lr=5e-05, batch_size=64, k_folds=5\n",
      "Validation | MSE: 32.8860, RMSE: 5.7068, MAE: 4.4930, MAPE: 7.00%, R2: 0.8858\n",
      "Test | MSE: 27.4593, RMSE: 5.2402, MAE: 4.2865, MAPE: 6.93%, R2: 0.8929\n",
      "\n",
      "Evaluating DeeperNet with lr=5e-05, batch_size=64, k_folds=5\n",
      "Validation | MSE: 43.1719, RMSE: 6.5585, MAE: 5.2798, MAPE: 8.17%, R2: 0.8419\n",
      "Test | MSE: 37.7023, RMSE: 6.1402, MAE: 5.0383, MAPE: 8.09%, R2: 0.8530\n",
      "\n",
      "Evaluating SimpleNet with lr=1e-05, batch_size=16, k_folds=5\n",
      "Validation | MSE: 30.8464, RMSE: 5.5322, MAE: 4.3638, MAPE: 6.75%, R2: 0.8909\n",
      "Test | MSE: 26.8545, RMSE: 5.1821, MAE: 4.2384, MAPE: 7.00%, R2: 0.8953\n",
      "\n",
      "Evaluating DeepNet with lr=1e-05, batch_size=16, k_folds=5\n",
      "Validation | MSE: 31.4344, RMSE: 5.5887, MAE: 4.4313, MAPE: 6.85%, R2: 0.8908\n",
      "Test | MSE: 26.8770, RMSE: 5.1843, MAE: 4.2256, MAPE: 6.87%, R2: 0.8952\n",
      "\n",
      "Evaluating DeeperNet with lr=1e-05, batch_size=16, k_folds=5\n",
      "Validation | MSE: 38.8634, RMSE: 6.2236, MAE: 4.9738, MAPE: 7.75%, R2: 0.8540\n",
      "Test | MSE: 31.1439, RMSE: 5.5807, MAE: 4.4985, MAPE: 6.95%, R2: 0.8785\n",
      "\n",
      "Evaluating SimpleNet with lr=1e-05, batch_size=32, k_folds=5\n",
      "Validation | MSE: 31.0478, RMSE: 5.5473, MAE: 4.3637, MAPE: 6.75%, R2: 0.8925\n",
      "Test | MSE: 27.2732, RMSE: 5.2224, MAE: 4.2617, MAPE: 7.04%, R2: 0.8936\n",
      "\n",
      "Evaluating DeepNet with lr=1e-05, batch_size=32, k_folds=5\n",
      "Validation | MSE: 31.7168, RMSE: 5.6108, MAE: 4.4191, MAPE: 6.86%, R2: 0.8884\n",
      "Test | MSE: 27.3538, RMSE: 5.2301, MAE: 4.2258, MAPE: 6.89%, R2: 0.8933\n",
      "\n",
      "Evaluating DeeperNet with lr=1e-05, batch_size=32, k_folds=5\n",
      "Validation | MSE: 34.7526, RMSE: 5.8861, MAE: 4.6900, MAPE: 7.29%, R2: 0.8651\n",
      "Test | MSE: 30.1645, RMSE: 5.4922, MAE: 4.4552, MAPE: 7.13%, R2: 0.8824\n",
      "\n",
      "Evaluating SimpleNet with lr=1e-05, batch_size=64, k_folds=5\n",
      "Validation | MSE: 31.9495, RMSE: 5.6268, MAE: 4.4139, MAPE: 6.83%, R2: 0.8944\n",
      "Test | MSE: 27.8972, RMSE: 5.2818, MAE: 4.3391, MAPE: 7.18%, R2: 0.8912\n",
      "\n",
      "Evaluating DeepNet with lr=1e-05, batch_size=64, k_folds=5\n",
      "Validation | MSE: 31.7563, RMSE: 5.6114, MAE: 4.4092, MAPE: 6.86%, R2: 0.8885\n",
      "Test | MSE: 28.4793, RMSE: 5.3366, MAE: 4.3391, MAPE: 7.17%, R2: 0.8889\n",
      "\n",
      "Evaluating DeeperNet with lr=1e-05, batch_size=64, k_folds=5\n",
      "Validation | MSE: 33.1544, RMSE: 5.7359, MAE: 4.4932, MAPE: 7.01%, R2: 0.8826\n",
      "Test | MSE: 27.3067, RMSE: 5.2256, MAE: 4.2111, MAPE: 6.75%, R2: 0.8935\n",
      "\n",
      "\n",
      "Best configuration for Validation MSE: {'model': 'SimpleNet', 'lr': 5e-05, 'batch_size': 32, 'k_folds': 5}\n",
      "Validation MSE: 30.7628\n",
      "Test MSE: 26.6891, RMSE: 5.1661, MAE: 4.2081, MAPE: 6.92%, R2: 0.8959\n",
      "\n",
      "Best configuration for Validation RMSE: {'model': 'SimpleNet', 'lr': 5e-05, 'batch_size': 32, 'k_folds': 5}\n",
      "Validation RMSE: 5.5251\n",
      "Test MSE: 26.6891, RMSE: 5.1661, MAE: 4.2081, MAPE: 6.92%, R2: 0.8959\n",
      "\n",
      "Best configuration for Validation MAE: {'model': 'SimpleNet', 'lr': 5e-05, 'batch_size': 32, 'k_folds': 5}\n",
      "Validation MAE: 4.3498\n",
      "Test MSE: 26.6891, RMSE: 5.1661, MAE: 4.2081, MAPE: 6.92%, R2: 0.8959\n",
      "\n",
      "Best configuration for Validation MAPE: {'model': 'SimpleNet', 'lr': 5e-05, 'batch_size': 32, 'k_folds': 5}\n",
      "Validation MAPE: 6.7185\n",
      "Test MSE: 26.6891, RMSE: 5.1661, MAE: 4.2081, MAPE: 6.92%, R2: 0.8959\n",
      "\n",
      "Best configuration for Validation R2: {'model': 'SimpleNet', 'lr': 1e-05, 'batch_size': 64, 'k_folds': 5}\n",
      "Validation R2: 0.8944\n",
      "Test MSE: 27.8972, RMSE: 5.2818, MAE: 4.3391, MAPE: 7.18%, R2: 0.8912\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "learning_rates = [0.0001, 0.00005, 0.00001]\n",
    "batch_sizes = [16, 32, 64]\n",
    "architectures = [SimpleNet, DeepNet, DeeperNet]\n",
    "k_folds_list = [3, 5]\n",
    "\n",
    "best_results = {\n",
    "    \"mse\": (float(\"inf\"), None, None),\n",
    "    \"rmse\": (float(\"inf\"), None, None),\n",
    "    \"mae\": (float(\"inf\"), None, None),\n",
    "    \"mape\": (float(\"inf\"), None, None),\n",
    "    \"r2\": (-float(\"inf\"), None, None),\n",
    "}\n",
    "\n",
    "for k_folds in k_folds_list:\n",
    "    for lr in learning_rates:\n",
    "        for bs in batch_sizes:\n",
    "            for arch in architectures:\n",
    "                print(f\"Evaluating {arch.__name__} with lr={lr}, batch_size={bs}, k_folds={k_folds}\")\n",
    "                avg_mse, avg_rmse, avg_mae, avg_mape, avg_r2, trained_model = train_model(\n",
    "                    arch, X_train_val_tensor, y_train_val_tensor, lr, bs, epochs=150, k_folds=k_folds\n",
    "                )\n",
    "                test_mse, test_rmse, test_mae, test_mape, test_r2 = test_model(trained_model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "                print(f\"Validation | MSE: {avg_mse:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}, MAPE: {avg_mape:.2f}%, R2: {avg_r2:.4f}\")\n",
    "                print(f\"Test | MSE: {test_mse:.4f}, RMSE: {test_rmse:.4f}, MAE: {test_mae:.4f}, MAPE: {test_mape:.2f}%, R2: {test_r2:.4f}\\n\")\n",
    "\n",
    "                # Update bests\n",
    "                metrics = {\n",
    "                    \"mse\": avg_mse,\n",
    "                    \"rmse\": avg_rmse,\n",
    "                    \"mae\": avg_mae,\n",
    "                    \"mape\": avg_mape,\n",
    "                    \"r2\": avg_r2\n",
    "                }\n",
    "                test_results = (test_mse, test_rmse, test_mae, test_mape, test_r2)\n",
    "                params = {'model': arch.__name__, 'lr': lr, 'batch_size': bs, 'k_folds': k_folds}\n",
    "\n",
    "                for metric in best_results:\n",
    "                    if (metric != \"r2\" and metrics[metric] < best_results[metric][0]) or (metric == \"r2\" and metrics[metric] > best_results[metric][0]):\n",
    "                        best_results[metric] = (metrics[metric], params, test_results)\n",
    "\n",
    "# Print best configurations and test results\n",
    "for metric in best_results:\n",
    "    val_score, params, test_scores = best_results[metric]\n",
    "    print(f\"\\nBest configuration for Validation {metric.upper()}: {params}\")\n",
    "    print(f\"Validation {metric.upper()}: {val_score:.4f}\")\n",
    "    print(f\"Test MSE: {test_scores[0]:.4f}, RMSE: {test_scores[1]:.4f}, MAE: {test_scores[2]:.4f}, MAPE: {test_scores[3]:.2f}%, R2: {test_scores[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6739ddee-f3fd-41b7-bdc5-5f68ffcb61ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SimpleNet with lr=0.002, batch_size=16, k_folds=3\n",
      "Validation | MSE: 58.4014, RMSE: 7.6173, MAE: 5.8981, MAPE: 9.28%, R2: 0.7545\n",
      "Test | MSE: 62.6831, RMSE: 7.9173, MAE: 6.4027, MAPE: 10.17%, R2: 0.7556\n",
      "\n",
      "Evaluating SimpleNet with lr=0.002, batch_size=32, k_folds=3\n",
      "Validation | MSE: 56.0416, RMSE: 7.4419, MAE: 5.8110, MAPE: 9.07%, R2: 0.7699\n",
      "Test | MSE: 60.8894, RMSE: 7.8032, MAE: 6.2631, MAPE: 9.99%, R2: 0.7625\n",
      "\n",
      "Evaluating SimpleNet with lr=0.002, batch_size=64, k_folds=3\n",
      "Validation | MSE: 47.1942, RMSE: 6.8681, MAE: 5.5342, MAPE: 8.46%, R2: 0.8313\n",
      "Test | MSE: 39.2007, RMSE: 6.2610, MAE: 5.2247, MAPE: 8.12%, R2: 0.8471\n",
      "\n",
      "Evaluating SimpleNet with lr=0.001, batch_size=16, k_folds=3\n",
      "Validation | MSE: 51.3335, RMSE: 7.1425, MAE: 5.7393, MAPE: 8.94%, R2: 0.7821\n",
      "Test | MSE: 51.4371, RMSE: 7.1720, MAE: 5.8943, MAPE: 9.54%, R2: 0.7994\n",
      "\n",
      "Evaluating SimpleNet with lr=0.001, batch_size=32, k_folds=3\n",
      "Validation | MSE: 45.8527, RMSE: 6.7702, MAE: 5.4244, MAPE: 8.45%, R2: 0.8315\n",
      "Test | MSE: 38.5406, RMSE: 6.2081, MAE: 4.9595, MAPE: 8.30%, R2: 0.8497\n",
      "\n",
      "Evaluating SimpleNet with lr=0.001, batch_size=64, k_folds=3\n",
      "Validation | MSE: 41.5514, RMSE: 6.4441, MAE: 5.0838, MAPE: 7.97%, R2: 0.8560\n",
      "Test | MSE: 33.9711, RMSE: 5.8285, MAE: 4.7677, MAPE: 7.67%, R2: 0.8675\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0005, batch_size=16, k_folds=3\n",
      "Validation | MSE: 43.8837, RMSE: 6.6168, MAE: 5.2546, MAPE: 8.17%, R2: 0.8248\n",
      "Test | MSE: 40.0810, RMSE: 6.3310, MAE: 5.1503, MAPE: 8.11%, R2: 0.8437\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0005, batch_size=32, k_folds=3\n",
      "Validation | MSE: 42.7021, RMSE: 6.5310, MAE: 5.2197, MAPE: 8.13%, R2: 0.8370\n",
      "Test | MSE: 33.3194, RMSE: 5.7723, MAE: 4.7894, MAPE: 7.63%, R2: 0.8701\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0005, batch_size=64, k_folds=3\n",
      "Validation | MSE: 37.4273, RMSE: 6.1121, MAE: 4.8037, MAPE: 7.47%, R2: 0.8545\n",
      "Test | MSE: 30.7742, RMSE: 5.5475, MAE: 4.5238, MAPE: 7.42%, R2: 0.8800\n",
      "\n",
      "Evaluating SimpleNet with lr=0.002, batch_size=16, k_folds=5\n",
      "Validation | MSE: 55.8483, RMSE: 7.4518, MAE: 5.9223, MAPE: 9.16%, R2: 0.7648\n",
      "Test | MSE: 52.9339, RMSE: 7.2756, MAE: 5.8758, MAPE: 9.53%, R2: 0.7936\n",
      "\n",
      "Evaluating SimpleNet with lr=0.002, batch_size=32, k_folds=5\n",
      "Validation | MSE: 49.5108, RMSE: 7.0284, MAE: 5.5839, MAPE: 8.63%, R2: 0.8299\n",
      "Test | MSE: 50.2845, RMSE: 7.0912, MAE: 5.7743, MAPE: 9.26%, R2: 0.8039\n",
      "\n",
      "Evaluating SimpleNet with lr=0.002, batch_size=64, k_folds=5\n",
      "Validation | MSE: 46.6275, RMSE: 6.8086, MAE: 5.4401, MAPE: 8.28%, R2: 0.8163\n",
      "Test | MSE: 39.8468, RMSE: 6.3124, MAE: 5.2347, MAPE: 8.20%, R2: 0.8446\n",
      "\n",
      "Evaluating SimpleNet with lr=0.001, batch_size=16, k_folds=5\n",
      "Validation | MSE: 52.4877, RMSE: 7.2259, MAE: 5.7826, MAPE: 8.97%, R2: 0.7986\n",
      "Test | MSE: 48.6759, RMSE: 6.9768, MAE: 5.4598, MAPE: 8.46%, R2: 0.8102\n",
      "\n",
      "Evaluating SimpleNet with lr=0.001, batch_size=32, k_folds=5\n",
      "Validation | MSE: 45.1135, RMSE: 6.7036, MAE: 5.3095, MAPE: 8.29%, R2: 0.8296\n",
      "Test | MSE: 37.8661, RMSE: 6.1535, MAE: 4.9797, MAPE: 7.84%, R2: 0.8523\n",
      "\n",
      "Evaluating SimpleNet with lr=0.001, batch_size=64, k_folds=5\n",
      "Validation | MSE: 40.6797, RMSE: 6.3641, MAE: 5.0582, MAPE: 7.92%, R2: 0.8641\n",
      "Test | MSE: 34.8168, RMSE: 5.9006, MAE: 4.8672, MAPE: 7.81%, R2: 0.8642\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0005, batch_size=16, k_folds=5\n",
      "Validation | MSE: 46.5525, RMSE: 6.8187, MAE: 5.3405, MAPE: 8.32%, R2: 0.8132\n",
      "Test | MSE: 41.6408, RMSE: 6.4530, MAE: 5.1850, MAPE: 8.20%, R2: 0.8376\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0005, batch_size=32, k_folds=5\n",
      "Validation | MSE: 41.1180, RMSE: 6.4028, MAE: 5.1041, MAPE: 7.93%, R2: 0.8591\n",
      "Test | MSE: 37.2759, RMSE: 6.1054, MAE: 5.1025, MAPE: 7.83%, R2: 0.8546\n",
      "\n",
      "Evaluating SimpleNet with lr=0.0005, batch_size=64, k_folds=5\n",
      "Validation | MSE: 35.2991, RMSE: 5.9191, MAE: 4.6565, MAPE: 7.31%, R2: 0.8550\n",
      "Test | MSE: 29.9088, RMSE: 5.4689, MAE: 4.4051, MAPE: 7.17%, R2: 0.8834\n",
      "\n",
      "\n",
      "Best configuration for Validation MSE: {'model': 'SimpleNet', 'lr': 0.0005, 'batch_size': 64, 'k_folds': 5}\n",
      "Validation MSE: 35.2991\n",
      "Test MSE: 29.9088, RMSE: 5.4689, MAE: 4.4051, MAPE: 7.17%, R2: 0.8834\n",
      "\n",
      "Best configuration for Validation RMSE: {'model': 'SimpleNet', 'lr': 0.0005, 'batch_size': 64, 'k_folds': 5}\n",
      "Validation RMSE: 5.9191\n",
      "Test MSE: 29.9088, RMSE: 5.4689, MAE: 4.4051, MAPE: 7.17%, R2: 0.8834\n",
      "\n",
      "Best configuration for Validation MAE: {'model': 'SimpleNet', 'lr': 0.0005, 'batch_size': 64, 'k_folds': 5}\n",
      "Validation MAE: 4.6565\n",
      "Test MSE: 29.9088, RMSE: 5.4689, MAE: 4.4051, MAPE: 7.17%, R2: 0.8834\n",
      "\n",
      "Best configuration for Validation MAPE: {'model': 'SimpleNet', 'lr': 0.0005, 'batch_size': 64, 'k_folds': 5}\n",
      "Validation MAPE: 7.3150\n",
      "Test MSE: 29.9088, RMSE: 5.4689, MAE: 4.4051, MAPE: 7.17%, R2: 0.8834\n",
      "\n",
      "Best configuration for Validation R2: {'model': 'SimpleNet', 'lr': 0.001, 'batch_size': 64, 'k_folds': 5}\n",
      "Validation R2: 0.8641\n",
      "Test MSE: 34.8168, RMSE: 5.9006, MAE: 4.8672, MAPE: 7.81%, R2: 0.8642\n"
     ]
    }
   ],
   "source": [
    "# Higher learning rates don't work with Deeper networks\n",
    "learning_rates = [0.002, 0.001, 0.0005]\n",
    "batch_sizes = [16, 32, 64]\n",
    "architectures = [SimpleNet]\n",
    "k_folds_list = [3, 5]\n",
    "\n",
    "best_results = {\n",
    "    \"mse\": (float(\"inf\"), None, None),\n",
    "    \"rmse\": (float(\"inf\"), None, None),\n",
    "    \"mae\": (float(\"inf\"), None, None),\n",
    "    \"mape\": (float(\"inf\"), None, None),\n",
    "    \"r2\": (-float(\"inf\"), None, None),\n",
    "}\n",
    "\n",
    "for k_folds in k_folds_list:\n",
    "    for lr in learning_rates:\n",
    "        for bs in batch_sizes:\n",
    "            for arch in architectures:\n",
    "                print(f\"Evaluating {arch.__name__} with lr={lr}, batch_size={bs}, k_folds={k_folds}\")\n",
    "                avg_mse, avg_rmse, avg_mae, avg_mape, avg_r2, trained_model = train_model(\n",
    "                    arch, X_train_val_tensor, y_train_val_tensor, lr, bs, epochs=150, k_folds=k_folds\n",
    "                )\n",
    "                test_mse, test_rmse, test_mae, test_mape, test_r2 = test_model(trained_model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "                print(f\"Validation | MSE: {avg_mse:.4f}, RMSE: {avg_rmse:.4f}, MAE: {avg_mae:.4f}, MAPE: {avg_mape:.2f}%, R2: {avg_r2:.4f}\")\n",
    "                print(f\"Test | MSE: {test_mse:.4f}, RMSE: {test_rmse:.4f}, MAE: {test_mae:.4f}, MAPE: {test_mape:.2f}%, R2: {test_r2:.4f}\\n\")\n",
    "\n",
    "                # Update bests\n",
    "                metrics = {\n",
    "                    \"mse\": avg_mse,\n",
    "                    \"rmse\": avg_rmse,\n",
    "                    \"mae\": avg_mae,\n",
    "                    \"mape\": avg_mape,\n",
    "                    \"r2\": avg_r2\n",
    "                }\n",
    "                test_results = (test_mse, test_rmse, test_mae, test_mape, test_r2)\n",
    "                params = {'model': arch.__name__, 'lr': lr, 'batch_size': bs, 'k_folds': k_folds}\n",
    "\n",
    "                for metric in best_results:\n",
    "                    if (metric != \"r2\" and metrics[metric] < best_results[metric][0]) or (metric == \"r2\" and metrics[metric] > best_results[metric][0]):\n",
    "                        best_results[metric] = (metrics[metric], params, test_results)\n",
    "\n",
    "# Print best configurations and test results\n",
    "for metric in best_results:\n",
    "    val_score, params, test_scores = best_results[metric]\n",
    "    print(f\"\\nBest configuration for Validation {metric.upper()}: {params}\")\n",
    "    print(f\"Validation {metric.upper()}: {val_score:.4f}\")\n",
    "    print(f\"Test MSE: {test_scores[0]:.4f}, RMSE: {test_scores[1]:.4f}, MAE: {test_scores[2]:.4f}, MAPE: {test_scores[3]:.2f}%, R2: {test_scores[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d1124566-b728-43a7-ba48-42962092cdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining with: lr=5e-05, batch_size=64, k_folds=5\n"
     ]
    }
   ],
   "source": [
    "# Retrain best model using best hyperparameters\n",
    "print(f\"Retraining with: lr={5e-05}, batch_size={32}, k_folds={5}\")\n",
    "\n",
    "# Retrain model\n",
    "_, _, _, _, _, simplenet_model = train_model(\n",
    "    SimpleNet,\n",
    "    X_train_val_tensor,\n",
    "    y_train_val_tensor,\n",
    "    5e-05,\n",
    "    32,\n",
    "    k_folds=5\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(simplenet_model.state_dict(), 'simplenet_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
